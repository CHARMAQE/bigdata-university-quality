# ğŸ›¡ï¸ Data Quality Pipeline â€” Academic Records

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.5+-orange.svg)](https://spark.apache.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.40+-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A comprehensive **data quality assessment and cleaning pipeline** for academic student records, built with **Apache Spark** for scalable processing and **Streamlit** for interactive monitoring.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Data Quality Metrics](#-data-quality-metrics)
- [Pipeline Details](#-pipeline-details)
- [Dashboard](#-dashboard)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

This project implements an end-to-end data quality solution for academic datasets containing:

| Field | Description | Example |
|-------|-------------|---------|
| `COD_ANU` | Academic year code | `2015` |
| `COD_ETU` | Student identifier | `12345678` |
| `COD_ELP` | Course/module code | `MATH1001` |
| `NOT_ELP` | Grade obtained | `14.5` |
| `COD_TRE` | Result status | `V`, `RAT`, `NV` |
| `COD_SES` | Exam session | `1` or `2` |

### Key Objectives

âœ… **Detect** data quality issues (missing values, duplicates, format errors)
âœ… **Clean** and normalize data using business rules
âœ… **Measure** quality through standardized metrics
âœ… **Monitor** quality evolution over time

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Quality Pipeline                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Raw     â”‚    â”‚           Spark Cluster             â”‚    â”‚Cleaned â”‚ â”‚
â”‚  â”‚  Data    â”‚â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”   â”‚â”€â”€â”€â–¶â”‚  Data  â”‚ â”‚
â”‚  â”‚  (.txt)  â”‚    â”‚  â”‚Load â”‚â–¶â”‚Cleanâ”‚â–¶â”‚Validâ”‚â–¶â”‚Writeâ”‚   â”‚    â”‚ (.csv) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â–¼                                    â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                  â”‚       Streamlit Dashboard           â”‚               â”‚
â”‚                  â”‚  â€¢ Quality Metrics  â€¢ Comparisons   â”‚               â”‚
â”‚                  â”‚  â€¢ Trend Analysis   â€¢ Data Explorer â”‚               â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### ğŸ”§ Data Processing
- **Smart CSV Parsing** â€” Handles malformed rows with embedded commas
- **Hierarchical Cleaning** â€” Each step prepares data for the next
- **Traceability** â€” Flags track all corrections (`row_status`, `*_flag`)

### ğŸ“Š Quality Metrics
- **7 Dimensions** measured: Completeness, Uniqueness, Coherence, Validity, Exactitude, Distribution, Schema Integrity
- **Weighted Global Score** for overall quality assessment
- **Before/After Comparison** to measure cleaning effectiveness

### ğŸ“ˆ Monitoring Dashboard
- **Real-time Metrics** visualization
- **Historical Tracking** of quality evolution
- **Column-level Analysis** and error drill-down
- **Export Capabilities** for reporting

---

## ğŸ“ Project Structure

```
projet-data-quality/
â”œâ”€â”€ ğŸ“‚ app/
â”‚   â””â”€â”€ streamlit_app.py          # Interactive dashboard
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ cleaners/              # Cleaning modules (PySpark)
â”‚   â”‚   â”œâ”€â”€ clean_cod_anu.py      # Year code normalization
â”‚   â”‚   â”œâ”€â”€ clean_cod_etud.py     # Student ID + deduplication
â”‚   â”‚   â”œâ”€â”€ clean_NOT_ELP.py      # Grade validation [0-20]
â”‚   â”‚   â”œâ”€â”€ cleaning_Code_ELP.py  # Module code format
â”‚   â”‚   â”œâ”€â”€ cleaning_COD_TRE.py   # Result status validation
â”‚   â”‚   â””â”€â”€ cleaning_cod_ses.py   # Session validation (1/2)
â”‚   â””â”€â”€ ğŸ“‚ jobs/
â”‚       â”œâ”€â”€ load_data.py          # Data ingestion job
â”‚       â””â”€â”€ run_cleaning.py       # Cleaning pipeline job
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                   # Source data
â”‚   â”‚   â””â”€â”€ dataset_metier.txt
â”‚   â”œâ”€â”€ ğŸ“‚ loaded_dataset/        # Ingested (Parquet)
â”‚   â”œâ”€â”€ ğŸ“‚ cleaned_data/          # Cleaned output (CSV)
â”‚   â””â”€â”€ metrics_history.csv       # Quality tracking
â”œâ”€â”€ ğŸ““ dq_metrics.ipynb           # Metrics exploration notebook
â”œâ”€â”€ ğŸ““ phase_exploration.ipynb    # Data exploration notebook
â”œâ”€â”€ ğŸ³ docker-compose.yml         # Spark cluster setup
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Python dependencies
â””â”€â”€ ğŸ“– README.md
```

---

## ğŸš€ Installation

### Prerequisites

- **Python 3.10+**
- **Docker & Docker Compose** (for Spark cluster)
- **Git**

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/projet-data-quality.git
cd projet-data-quality
```

### 2. Install Python Dependencies

```bash
python -m pip install -r requirements.txt
```

### 3. Start Spark Cluster

```bash
docker-compose up -d
```

Verify the cluster is running:
- **Spark Master UI**: http://localhost:8080
- **Spark Worker UI**: http://localhost:8081

---

## ğŸ’» Usage

### Option 1: Streamlit Dashboard (Recommended)

```bash
streamlit run app/streamlit_app.py
```

Then open http://localhost:8501 in your browser.

**Dashboard Workflow:**
1. **âš™ï¸ Actions** tab â†’ Click "ğŸ“¥ Lancer Ingestion" to load raw data
2. **âš™ï¸ Actions** tab â†’ Click "ğŸ§¹ Lancer Nettoyage" to clean data
3. **ğŸ“Š Vue d'ensemble** tab â†’ View quality metrics and comparisons
4. **ğŸ” Analyse DÃ©taillÃ©e** tab â†’ Explore columns and errors

### Option 2: Command Line (Spark Jobs)

```bash
# Step 1: Ingest raw data
docker exec spark-master_1 bash -c \
  "PYTHONPATH=/opt/project/src /opt/spark/bin/spark-submit \
   --master local[*] /opt/project/src/jobs/load_data.py"

# Step 2: Run cleaning pipeline
docker exec spark-master_1 bash -c \
  "PYTHONPATH=/opt/project/src /opt/spark/bin/spark-submit \
   --master local[*] /opt/project/src/jobs/run_cleaning.py"
```

### Option 3: Jupyter Notebooks

```bash
jupyter notebook dq_metrics.ipynb
```

---

## ğŸ“ Data Quality Metrics

| Metric | Weight | Description |
|--------|--------|-------------|
| **ComplÃ©tude** | 20% | % of non-null, non-empty values |
| **ValiditÃ©** | 20% | Values conform to business rules (sessions, result codes) |
| **IntÃ©gritÃ© SchÃ©ma** | 20% | Rows with correct structure (not INVALID) |
| **Exactitude** | 15% | Grades within valid range [0, 20] |
| **CohÃ©rence** | 15% | Business rule consistency (note â†” status) |
| **UnicitÃ©** | 5% | No duplicates on key (ETU, ELP, SES) |
| **Distribution** | 5% | Balanced session distribution |

### Global Score Formula

```
Score = 0.20Ã—ComplÃ©tude + 0.20Ã—ValiditÃ© + 0.20Ã—SchÃ©ma
      + 0.15Ã—Exactitude + 0.15Ã—CohÃ©rence
      + 0.05Ã—UnicitÃ© + 0.05Ã—Distribution
```

---

## ğŸ”„ Pipeline Details

### Cleaning Steps (Hierarchical)

```
1. COD_ANU  â†’ Format YYYY normalization, flag corrections
      â†“
2. COD_ETU  â†’ Null detection, duplicate removal (business key)
      â†“
3. COD_ELP  â†’ Uppercase, trim, validate 8-char alphanumeric
      â†“
4. NOT_ELP  â†’ Numeric conversion, range check [0-20], coherence
      â†“
5. COD_TRE  â†’ Validate against allowed codes (V, RAT, NV, ADM...)
      â†“
6. COD_SES  â†’ Must be 1 or 2, flag invalid sessions
```

### Generated Flags

| Flag | Meaning |
|------|---------|
| `row_status` | `OK` / `FIXED` / `INVALID` |
| `cod_anu_was_corrected` | Year format was normalized |
| `elp_invalid_format` | Module code doesn't match expected format |
| `note_out_of_range` | Grade outside [0, 20] |
| `note_incoherent` | Grade doesn't match result status |
| `dup_business_flag` | Duplicate on business key |

---

## ğŸ“¸ Dashboard Preview

### Quality Radar Chart
![Radar Chart](docs/radar_chart.png)

### Before/After Comparison
![Comparison](docs/comparison.png)

---

## ğŸ› ï¸ Development

### Running Tests

```bash
python -m pytest tests/ -v
```

### Code Style

```bash
# Format code
black src/ app/

# Lint
flake8 src/ app/
```

### Adding New Cleaners

1. Create a new file in `src/cleaners/`
2. Implement a function `clean_<field>_spark(df: DataFrame) -> DataFrame`
3. Add the import and call in `src/jobs/run_cleaning.py`

---

## ğŸ“¦ Deployment

### Stop Spark Cluster

```bash
docker-compose down
```

### Clean Data Outputs

```bash
rm -rf data/loaded_dataset/output/*
rm -rf data/cleaned_data/output/*
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Hamza Charmaqe**
Master's Student â€” Data Quality Project 2025

---

## ğŸ™ Acknowledgments

- Apache Spark for distributed processing
- Streamlit for rapid dashboard development
- pandas & numpy for data manipulation